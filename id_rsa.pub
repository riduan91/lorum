# stpDMIRESGData

## **Process logic**

- **Data Preparation & Scope Validation**: Loads ESG scope data containing portfolio instruments and validates instrument types against predefined criteria. Creates temporary staging tables for each ESG metric category (scores, CO2, diversity, human rights, controverse, engagement, groups).

- **Temporal Data Joining & Score Aggregation**: For each ESG metric, performs temporal joins between scope instruments and sustainability scoring tables using latest available data logic. Applies COALESCE hierarchy where instrument-level scores override issuer-level scores when available.

- **Coverage Calculation & Score Weighting**: Computes potential coverage totals by portfolio and reporting date, then calculates effective coverage weights. Merges all ESG metrics and computes weighted score contributions using effective coverage methodology to produce final ESG indicators.

## File Used as Inputs

| File Name | Description |
| :-------: | :-------: |
|  `/opt/airflow/data/lookthrough/#esgscope.parquet` or `/opt/airflow/data/benchmark/#esgscope.parquet` | The scope from Lookthrough or Benchmark batch to compute ESG indicators |

## Tables Used as Inputs

| Table Name | Description |
| :-------: | :-------: |
| `DWGN.tblDWGNSustainabilityScores_Issr_ESG` | Stores issuer, instrument ESG data. |
| `DWGN.tblDWGNSustainabilityScores_Issr_CO2` | Stores issuer CO2 data. |
| `DWGN.tblDWGNSustainabilityScores_Inst_ESG` | Stores instrument ESG data. |
| `DWGN.tblDWGNSustainabilityScores_Inst_CO2` | Stores instrument CO2 data. |
| `DWGN.tblDWGNSustainabilityScores_Diversity` | Stores diversity data. |
| `DWGN.tblDWGNSustainabilityScores_HumanRights` | Stores human rights data. |
| `DWGN.tblDWGNSustainabilityScores_Controverse` | Stores controverse data. |
| `DWGN.tblDWGNSustainabilityScores_Engagement` | Stores engagement data. |
| `DWGN.tblDWGNSustainabilityScores_Groups` | Stores groups data. |

---

## Target File

| Table Name | Description |
| :-------: | :-------: |
| `/opt/airflow/esg/esg_results_<audit_id>_0.parquet` | File containing ESG indicators computed for benchmark or lookthrough scopes. |

---

## Temporary (Staging) Tables

| Temporary Table | Purpose / Description | Equivalent Parquet |
| :-------: | :-------: | :-------: |
| `#ESG_POTENTIAL_COV` | Computes potential coverage for eligible instruments based on instrument type validation. | `potential_coverage_0.parquet` |
| `#ESG_SCORE` | Stores Global, environment and social scores using COALESCE logic (instrument scores override issuer scores when available).| `esg_0.parquet` |
| `#ESG_INTENSITY` | Stores CO2 intensity and emissions data with thematic source identification (INST-GREEN vs ISSR). | `co2_0.parquet` |
| `#ESG_DIVERSITY` | Stores gender diversity KPI data from issuer-level sustainability scores. | `diversity_0.parquet` |
| `#ESG_HUMANRIGHTS` | Stores human rights KPI data from issuer-level sustainability scores. | `hr_0.parquet` |
| `#ESG_CONTROVERSE` | Stores controverse exposure data (ESG and Social) from issuer-level sustainability scores. | `controverse_0.parquet` |
| `#ESG_ENGAGEMENT` | Stores engagement data (Environment, Social, Governance) filtered by previous calendar year. | `engagement_0.parquet` |
| `#ESG_GROUP` | Stores group policy recommendation data with coverage weights for 'OUT' policies. | `group_0.parquet` |
| `#ESG_PotentialCovTot` | Computes the potential coverage totals grouped by portfolio and reporting date. | `potential_coverage_total_0.parquet` |
| `#ESG_summaryTable` | Aggregates effective coverage weights by portfolio and date for score contribution calculations. | Computed in memory during merge |
| `#ESG_ALL` | Combines all above scores into the final ESG output with effective coverage calculations and score contributions. | `esg_results_<audit_id>_0.parquet` |

---

## Task Breakdown for the Airflow DAG

| Task Name | Description | Stored data | GETDATE Marker | Parallelizable?|
| :-------: | :-------: | :-------: | :-------: |:-------: |
| **1. `print_scope`** | Validates and logs ESG scope data for debugging purposes. | XCom examples and row count | - | No |
| **2. `process_esg`** | Processes ESG scores using merge_asof for temporal joins with issuer and instrument data. | `esg_0.parquet` | - | Yes |
| **3. `process_co2`** | Processes CO2 intensity and emissions data with thematic source classification. | `co2_0.parquet` | - | Yes |
| **4. `process_diversity`** | Processes gender diversity KPI data using temporal joins with issuer data. | `diversity_0.parquet` | - | Yes |
| **5. `process_humanrights`** | Processes human rights KPI data using temporal joins with issuer data. | `hr_0.parquet` | - | Yes |
| **6. `process_controverse`** | Processes controverse exposure data using temporal joins with issuer data. | `controverse_0.parquet` | - | Yes |
| **7. `process_engagement`** | Processes engagement data filtered by previous calendar year window. | `engagement_0.parquet` | - | Yes |
| **8. `process_group`** | Processes group policy data with OUT policy identification. | `group_0.parquet` | - | Yes |
| **9. `compute_potential_coverage` | Computes potential coverage totals for effective coverage normalization. | `potential_coverage_total_0.parquet` | - | No |
| **10. `combine_all`** | Merges all ESG metrics, computes effective coverage, and calculates score contributions. | `esg_results_<audit_id>_0.parquet` | - | No |

---

## High-Level DAG Structure Diagram

<img src="https://mermaid.ink/svg/pako:eNp9VO9r2zAQ_VeEoLCFNPhnEvvDoHXSfBobLJ9Wl6HYV1sslox0Lu1C_vee7WZxoLE-WffeO90963Tgmc6Bx7wwoi7ZdpUqRuvmhm2F_csKo5uaOW4ftc2up92xx5_CiP0e9syiMMiQ2Papp7UrlwYylFqx7f056rh3Xx4nk43AEgwD9SKNVhUoZELlzOpMCkqYaQN2Mnn6OhTeD4TJD-8KKxmwcvkCxkp8u8JdDbhlUwnFjCxKtFfo6wE90wqNbtPDFfbDRZ-FKKBr83PyZkDuHP-8hg5y3D_wKrFVrFXeEy4MZre33y6oFy6OoskouhpF16Powyi6GUFB5acGLULteG3nia7qBsEysozVGsna9uZk7S8hqxlqFPuBe53S_1DupCIlXV4mdiT4sJpJhbrL9ywV5Vr_2jDdIB1zTnMqhKYj0Ur1F9z2sWH1XTt9tcPKz2GfT2ngZM5jNA1MeQWmEu2WH1pByqmOClIe06eCBmnUUp6qI8lqoX5rXZ2UdGpR8viZ2qVdU-cCYSUFjWn1P2rIQzCJbhTy2PW7HDw-8Fcee-FiNg-jZbCIPD-KgnA-5W88DoOZ4wR-EPmR5wULLzpO-b_uVGe2dKN56IZB4ESBswwXUw65RG2-9-9I95wc3wEiUEm2" width="100%">

<!-- 
:::mermaid
graph TD
    %% Task group 01
    subgraph A [Parallel start tasks]
        direction TB
        01A([**Gather environment and social scores**])
        01B([**Gather CO2 scores**])
        01C([**Gather diversity scores**])
        01D([**Gather human rights scores**])
        01E([**Gather controverse scores**])
        01F([**Gather engagement scores**])
        01G([**Gather groups scores**])
        group01_exit([**End**])

        01A -- > group01_exit
        01B -- > group01_exit
        01C -- > group01_exit
        01D -- > group01_exit
        01E -- > group01_exit
        01F -- > group01_exit
        01G -- > group01_exit
        end

    step02([**Computes the potential coverage totals**])
    step03([**Combines all above scores into the final ESG output**])
    

    %% Connections
    group01_exit -- > step02
    step02 -- > step03

:::
> If the mermaid diagram above does not show in VS Code Preview, please install the `Markdown Preview Mermaid Support` extension.
> Remove the empty space in the connection arrows "-- >" for Mermaid Live Editor to display the diagram properly.
-->

---

## Python Migration Divergences and Optimizations

### **Key Architectural Changes**

1. **Temporal Join Strategy**: SQL uses complex window functions with `RANK() OVER (PARTITION BY ... ORDER BY ...)` for latest data selection. Python replaces this with `pandas.merge_asof()` which is specifically designed for temporal joins and provides better performance for time-series data.

2. **Memory Management**: SQL creates multiple large temporary tables (`#ESG_SCORE`, `#ESG_INTENSITY`, etc.) simultaneously in memory. Python processes each ESG metric independently and stores results in separate parquet files, reducing peak memory usage.

3. **Data Processing Flow**: SQL uses sequential processing with temporary table dependencies. Python parallelizes independent ESG metric processing (tasks 2-8) while maintaining dependencies only where necessary (coverage calculation and final merge).

### **Performance Optimizations** 

1. **Vectorized Operations**: Python leverages pandas vectorization for coverage weight calculations, replacing SQL's row-by-row `CASE` statements with `numpy.where()` operations that process entire arrays at once.

2. **Efficient Data Types**: Python uses pandas dtype optimization and parquet compression for better I/O performance compared to SQL temporary tables stored in memory.

3. **Parallel Task Execution**: The DAG structure allows tasks 2-8 to run in parallel since they're independent, unlike the sequential SQL approach that processes each metric one after another.
