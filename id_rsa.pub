# --- prepare alpha lookup (same as you do) ---
alpha_df_lookup = (
    alpha_df.add_suffix("_alpha")
            .rename(columns={
                "strInstAladdin_alpha": "strInstAladdin",
                "datPeriodLastDay_alpha": "datPeriodLastDay",
                "numReportPortfGroupID_alpha": "numReportPortfGroupID",
                "strPortfIDNumPart_alpha": "strPortfIDNumPart",
            })
)

# Keep only needed columns early
alpha_keep = [
    "strInstAladdin", "datPeriodLastDay", "numReportPortfGroupID", "strPortfIDNumPart",
    "numDeltaAdjedNotionalValu_alpha", "numPosQty_alpha",
]
alpha_df_lookup = alpha_df_lookup[alpha_keep]

# Build a tiny DF of eligible instruments (no large boolean array)
elig_df = pd.DataFrame({"strInstAladdin": list(set(eligible_alpha))})

# Carry original row ids for in-place updates without set_index
df_tmp = df_tmp.copy()
df_tmp["__rid__"] = np.arange(len(df_tmp), dtype=np.int64)

keys = ["strInstAladdin", "datPeriodLastDay", "numReportPortfGroupID", "strPortfIDNumPart"]

# 1) only the rows in df_tmp that are eligible
cands = df_tmp[["__rid__", "numHoldQuantity"] + keys].merge(elig_df, on="strInstAladdin", how="inner")

# 2) only the candidates that have alpha data (inner join)
patch = cands.merge(alpha_df_lookup, on=keys, how="inner")

# 3) drop bad rows and compute
mask_valid = patch["numDeltaAdjedNotionalValu_alpha"].notna() & patch["numPosQty_alpha"].notna() & (patch["numPosQty_alpha"] != 0)
patch = patch.loc[mask_valid]

new_delta = (patch["numDeltaAdjedNotionalValu_alpha"].to_numpy() / patch["numPosQty_alpha"].to_numpy()) * patch["numHoldQuantity"].to_numpy()

# 4) in-place write back using original row ids
rows = patch["__rid__"].to_numpy()
df_tmp.loc[rows, "numDeltaAdjustedSpread"] = new_delta
df_tmp.loc[rows, "OriginalQty"] = patch["numPosQty_alpha"].to_numpy()

# (optional) drop helper
df_tmp.drop(columns="__rid__", inplace=True)
